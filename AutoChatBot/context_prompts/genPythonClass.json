[
    {
        "role": "system",
        "content": "You are a computer programm that writes code for python classes and nothing else."
    },
    {
        "role": "user",
        "content": "Write python code that can read a json of the form:\n\n    [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n    ]\n\nCall the Class ConversationJsonReader and let it have two methods, one to read a json and return a dictionary and another one to validate that the json has the expected structure."
    },
    {
        "role": "assistant",
        "content": "import json\n\nclass ConversationJsonReader:\n    \"\"\"\n    ConversationJsonReader: This class reads JSON files containing conversations in a specific format and validates them.\n    \n    Init parameters:\n    - file_path (str): Path to the JSON file to be read.\n    \n    Main methods:\n    - read_file(file_path=None): Reads the JSON file and returns the conversation as a list of dictionaries.\n    \n    Example usage:\n        reader = ConversationJsonReader(file_path=\"conversations.json\")\n        conversations = reader.read_file()\n        print(conversations)\n        \n    Input:\n    - file_path (str, optional): Path to the JSON file to be read. If not provided, the file path specified during class initialization is used.\n    \n    Output:\n    - conversations (list of dicts): List containing dictionaries representing the conversation. Each dictionary should have \"role\" and \"content\" keys.\n    \n    Raises:\n    - FileNotFoundError: If the specified file path does not exist.\n    - ValueError: If the JSON file does not adhere to the expected conversation format.\n    \n    Example JSON format:\n    [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n    ]\n    \"\"\"\n\n    def __init__(self, file_path=None):\n        self.file_path = file_path\n\n    def read_file(self, file_path=None):\n        \"\"\"\n        Reads the JSON file and returns the conversation as a list of dictionaries.\n        \n        Args:\n        - file_path (str, optional): Path to the JSON file to be read. If not provided, the file path specified during class initialization is used.\n        \n        Returns:\n        - conversations (list of dicts): List containing dictionaries representing the conversation. Each dictionary should have \"role\" and \"content\" keys.\n        \n        Raises:\n        - FileNotFoundError: If the specified file path does not exist.\n        - ValueError: If the JSON file does not adhere to the expected conversation format.\n        \"\"\"\n        try:\n            # Step 1: Check if a file_path is provided, if yes, update self.file_path\n            if file_path:\n                self.file_path = file_path\n            \n            # Step 2: Open the JSON file in read mode\n            with open(self.file_path, 'r') as file:\n                # Step 3: Load the JSON content from the file\n                content = json.load(file)\n                # Step 4: Validate the conversation format\n                self._validate_conversation(content)\n                # Step 5: Return the conversation\n                return content\n        except FileNotFoundError:\n            # Step 6: Handle FileNotFoundError and raise an appropriate exception\n            raise FileNotFoundError(f\"File not found. Please check the path '{self.file_path}' and try again.\")\n    \n    def _validate_conversation(self, conversation):\n        \"\"\"\n        Validates the conversation JSON format.\n        \n        Args:\n        - conversation (list of dicts): List containing dictionaries representing the conversation.\n        \n        Raises:\n        - ValueError: If the JSON file does not adhere to the expected conversation format.\n        \"\"\"\n        # Step 1: Check if the conversation is a list\n        if not isinstance(conversation, list):\n            # Step 2: Raise ValueError if the conversation is not a list\n            raise ValueError(\"Conversation JSON must contain a list of dictionaries.\")\n        \n        # Step 3: Iterate through each item in the conversation\n        for item in conversation:\n            # Step 4: Check if each item is a dictionary and contains \"role\" and \"content\" keys\n            if not isinstance(item, dict) or \"role\" not in item or \"content\" not in item:\n                # Step 5: Raise ValueError if the format is incorrect\n                raise ValueError(\"Conversation JSON must contain dictionaries with 'role' and 'content' keys.\")\n\nif __name__ == '__main__':\n    # Step 1: Create an instance of ConversationJsonReader with a specified file_path\n    reader = ConversationJsonReader(file_path=\"conversations.json\")\n    # Step 2: Read the file and get the conversations\n    conversations = reader.read_file()\n    # Step 3: Print the conversations\n    print(conversations)"
    },
    {
        "role": "user",
        "content": "Write python code that takes a directory containing json object and is able to return them as dictionaries. The code shall have two methods, one for retrieving a dictionary from a specific json and one to retrieve all names of available jsons. The class name shall be ContextManager and the class shall use ConversationJsonReader from ConversationJsonReader which I wrote to retrieve the JSON data."
    },
    {
        "role": "assistant",
        "content": "import os\nfrom ConversationJsonReader import ConversationJsonReader\n\nclass ContextManager:\n    \"\"\"\n    A class for managing context stored in multiple JSON files.\n\n    This class provides methods to retrieve context based on the file name.\n\n    Steps:\n    1. Initialize the ContextManager with the folder path containing JSON files.\n    2. Use retrieve_context() method to get context for a specific context file.\n    3. Use get_all_context_names() method to get a list of all existing context names.\n\n    Usage:\n    context_folder = 'context_prompts'\n    manager = ContextManager(context_folder)\n    context_name = 'example_context.json'\n    retrieved_context = manager.retrieve_context(context_name)\n    print(retrieved_context)\n    [{'role': 'example_context', 'content': 'You are a helpful assistant.'}]\n    \"\"\"\n\n    def __init__(self, context_folder='context_prompts'):\n        \"\"\"\n        Initialize the ContextManager with the folder path containing JSON files.\n\n        Args:\n        - context_folder (str): Folder path containing JSON files representing context.\n        \"\"\"\n        self.context_folder = context_folder\n        self.context_data = self.load_context_data()\n\n    def load_context_data(self):\n        \"\"\"\n        Load context data from JSON files into memory.\n\n        Returns:\n        - dict: Dictionary containing context data loaded from JSON files.\n        \"\"\"\n        context_data = {}\n        for file_name in os.listdir(self.context_folder):\n            if file_name.endswith(\".json\"):\n                file_path = os.path.join(self.context_folder, file_name)\n                context_data[file_name] = ConversationJsonReader().read_file(file_path)\n        return context_data\n\n    def retrieve_context(self, context_name):\n        \"\"\"\n        Retrieve context from a specific context file.\n\n        Args:\n        - context_name (str): Name of the context file.\n\n        Returns:\n        - list of dict or str: Context data from the specified file, or a message indicating no context found.\n\n        Notes:\n        - If the specified context file does not exist, a message will be returned.\n        \"\"\"\n        if context_name in self.context_data:\n            return self.context_data[context_name]\n        else:\n            return f\"Context file '{context_name}' does not exist.\"\n\n    def get_all_context_names(self):\n        \"\"\"\n        Get a list of all existing context names.\n\n        Returns:\n        - list: List of strings containing all existing context names.\n        \"\"\"\n        return list(self.context_data.keys())\n\n\n# Usage example:\nif __name__ == \"__main__\":\n    # Initialize the ContextManager with the folder path containing JSON files\n    context_folder = 'context_prompts'\n    manager = ContextManager(context_folder)\n\n    # Retrieve context from a specific context file\n    context_name = 'banana.json'\n    retrieved_context = manager.retrieve_context(context_name)\n    print(retrieved_context)  # Output: [{'role': 'system', 'content': 'You are a helpful assistant.'}]\n\n    # Get all existing context names\n    all_context_names = manager.get_all_context_names()\n    print(all_context_names)"
    },
    {
        "role": "user",
        "content": "Write python code that can interface with the openai api using requests. The code shall be able to load an api key from an .env file, use the endpoint url 'https://api.openai.com/v1/chat/completions'\n\nThe request shall have following content:\n\n        data = {\n            \"model\": model,\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens,\n            \"stop\": stop_sequences,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty,\n            \"top_p\": top_p,\n            \"messages\": conversation\n        }\n        headers = {\n            'Authorization': f'Bearer {self.api_key}',\n            'Content-Type': 'application/json'\n        }\n\nAnd the expected response has the form:\n\n        {\n            'id': 'chatcmpl-939gfxWbMKlqGh8hkPG5IvEO6SYDq',\n            'object': 'chat.completion',\n            'created': 1710539249,\n            'model': 'gpt-3.5-turbo-0125',\n            'choices': [{\n                'index': 0,\n                'message': {'role': 'assistant', 'content': 'The Los Angeles Dodgers won the 2020 World Series'},\n                'logprobs': None,\n                'finish_reason': 'stop'\n            }],\n            'usage': {'prompt_tokens': 19, 'completion_tokens': 9, 'total_tokens': 28},\n            'system_fingerprint': 'fp_4f2ebda25a'\n        }"
    },
    {
        "role": "assistant",
        "content": "import os\nfrom dotenv import load_dotenv\nimport requests\nimport argparse\n\nclass GPT3ChatCompletion:\n    \"\"\"\n    GPT3ChatCompletion: This class handles OpenAI API chat completion requests.\n    \n    Init parameters:\n    - api_key (str, optional): The API key for authentication with the OpenAI API.\n    - model (str): The model to be used for chat completion. Default is \"gpt-3.5-turbo\".\n    - temperature (float): Controls randomness in the generation. Lower values make the generation more deterministic.\n    - max_tokens (int): The maximum number of tokens to generate. Requests can use up to 4096 tokens shared between prompt and completion.\n    - stop_sequences (list[str], optional): Sequences where the API should stop generating further tokens.\n    - frequency_penalty (float): The penalty for frequency of tokens in the generated text.\n    - presence_penalty (float): The penalty for new tokens based on their presence in the text so far.\n    - top_p (float): Nucleus sampling parameter. A higher value means more diversity in the generation.\n    \n    Main method:\n    - make_api_request(conversation): Sends a request to the OpenAI API with the specified conversation and returns the response.\n    \n    Example usage:\n        conversation = [{\"role\": \"user\", \"content\": \"Hello, who won the world series in 2020?\"}]\n        chat_completion = GPT3ChatCompletion(model=\"gpt-3.5-turbo\", max_tokens=100)\n        response = chat_completion.make_api_request(conversation)\n    \n    Response object example:\n        {\n            'id': 'chatcmpl-939gfxWbMKlqGh8hkPG5IvEO6SYDq',\n            'object': 'chat.completion',\n            'created': 1710539249,\n            'model': 'gpt-3.5-turbo-0125',\n            'choices': [{\n                'index': 0,\n                'message': {'role': 'assistant', 'content': 'The Los Angeles Dodgers won the 2020 World Series'},\n                'logprobs': None,\n                'finish_reason': 'stop'\n            }],\n            'usage': {'prompt_tokens': 19, 'completion_tokens': 9, 'total_tokens': 28},\n            'system_fingerprint': 'fp_4f2ebda25a'\n        }\n    \"\"\"\n\n    def __init__(self, api_key=None, model=\"gpt-3.5-turbo\", temperature=1, max_tokens=100, stop_sequences=None, frequency_penalty=0, presence_penalty=0, top_p=1):\n        load_dotenv()\n        self.api_key = api_key if api_key else os.getenv(\"OPENAI_API_KEY\")\n        self.model = model\n        self.temperature = temperature\n        self.max_tokens = max_tokens\n        self.stop_sequences = stop_sequences\n        self.frequency_penalty = frequency_penalty\n        self.presence_penalty = presence_penalty\n        self.top_p = top_p\n        self.endpoint_url = 'https://api.openai.com/v1/chat/completions'\n\n    def update_attributes(self, **kwargs):\n        for key, value in kwargs.items():\n            if hasattr(self, key):\n                setattr(self, key, value)\n            else:\n                raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\n    def make_api_request(\n            self,\n            conversation,\n            model=None,\n            temperature=None,\n            max_tokens=None,\n            stop_sequences=None,\n            frequency_penalty=None,\n            presence_penalty=None,\n            top_p=None\n            ):\n\n        # Use Class defaults if None are provided\n        model = model if model is not None else self.model\n        temperature = temperature if temperature is not None else self.temperature\n        max_tokens = max_tokens if max_tokens is not None else self.max_tokens\n        stop_sequences = stop_sequences if stop_sequences is not None else self.stop_sequences\n        frequency_penalty = frequency_penalty if frequency_penalty is not None else self.frequency_penalty\n        presence_penalty = presence_penalty if presence_penalty is not None else self.presence_penalty\n        top_p = top_p if top_p is not None else self.top_p\n\n        # The following check does not work if the input is not a dict\n        if conversation is None:\n            raise ValueError(\"No question was asked\")\n        if isinstance(conversation, str): \n            conversation = [\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n                {\"role\": \"user\", \"content\": conversation}\n            ]\n        data = {\n            \"model\": model,\n            \"temperature\": temperature,\n            \"max_tokens\": max_tokens,\n            \"stop\": stop_sequences,\n            \"frequency_penalty\": frequency_penalty,\n            \"presence_penalty\": presence_penalty,\n            \"top_p\": top_p,\n            \"messages\": conversation\n        }\n        headers = {\n            'Authorization': f'Bearer {self.api_key}',\n            'Content-Type': 'application/json'\n        }\n        response = requests.post(self.endpoint_url, headers=headers, json=data)\n        return response.json()\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser(description=\"Command Line Interface for GPT-3 Chat Completion\")\n    parser.add_argument(\"--model\", type=str, default=\"gpt-3.5-turbo\", help=\"Model name for the OpenAI completion request.\")\n    parser.add_argument(\"--max_tokens\", type=int, default=100, help=\"Maximum number of tokens to generate in the completion.\")\n    parser.add_argument(\"--temperature\", type=float, default=1, help=\"Controls randomness: lower values make completions more deterministic.\")\n    parser.add_argument(\"--frequency_penalty\", type=float, default=0, help=\"Penalty for frequent tokens, increasing this value produces more varied results.\")\n    parser.add_argument(\"--presence_penalty\", type=float, default=0, help=\"Penalty for new tokens, increasing this value encourages new tokens in the completion.\")\n    parser.add_argument(\"--top_p\", type=float, default=1, help=\"Nucleus sampling: top p of the probability mass is considered for sampling.\")\n    parser.add_argument(\"--stop_sequences\", nargs='*', help=\"Sequences where the API should stop generating further tokens.\")\n    parser.add_argument(\"--question\", type=str, help=\"The question or prompt to ask the model.\")\n\n    args = parser.parse_args()\n    chat_completion = GPT3ChatCompletion(\n        model=args.model,\n        max_tokens=args.max_tokens,\n        temperature=args.temperature,\n        frequency_penalty=args.frequency_penalty,\n        presence_penalty=args.presence_penalty,\n        top_p=args.top_p,\n        stop_sequences=args.stop_sequences\n    )\n\n    conversation = [\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": args.question}\n    ]\n    \n    response = chat_completion.make_api_request(conversation)\n    print(\"Chat Completion Response:\", response)"
    }
]